{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from custom_dataset import CustomDataset, make_data, make_roberta_data, RobertaDataset\n",
    "from model import BaseModel, RobertaDocument, RobertaLinear\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from arguments import parse_args\n",
    "from collections import defaultdict\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "num_cores = os.cpu_count()\n",
    "args = parse_args()\n",
    "seed_everything(args.seed)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, test,label_encoder = make_roberta_data(args)\n",
    "test = test.reset_index(drop =True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.PLM)\n",
    "config = AutoConfig.from_pretrained(args.PLM)\n",
    "\n",
    "test_dataset = RobertaDataset(\n",
    "    test.reset_index(drop=True),\n",
    "    tokenizer,\n",
    "    args.max_input_length,\n",
    "    None\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size = args.batch_size, shuffle=False, num_workers = num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_ensemble(model_dir, test_loader, device):\n",
    "    softmax_layer = nn.Softmax(dim=1)\n",
    "    dirs = os.listdir(model_dir)\n",
    "    dirs = sorted(dirs)\n",
    "    print(\"@@@@@@@@@@@@@@@@@@@@@\")\n",
    "    print(dirs)\n",
    "    print(\"@@@@@@@@@@@@@@@@@@@@@\")\n",
    "\n",
    "    type_preds, polarity_preds, tense_preds, certainty_preds = [], [], [], []\n",
    "\n",
    "    for i in range(len(dirs)):\n",
    "        tmp_dirs = os.listdir(os.path.join(model_dir,dirs[i]))\n",
    "        tmp_dirs = sorted(tmp_dirs)\n",
    "\n",
    "        config = AutoConfig.from_pretrained(args.PLM)\n",
    "        config.model_name = args.model_name\n",
    "\n",
    "        print(\"@@@@@@@@@@@@@@@@\")\n",
    "        print(\"model_load start\")\n",
    "\n",
    "        print(f\"model : {tmp_dirs[1]}\")\n",
    "        print(f\"model_state_dict : {tmp_dirs[0]}\")\n",
    "        \n",
    "        model = torch.load(os.path.join(model_dir,dirs[i],tmp_dirs[1]))\n",
    "        model.load_state_dict(torch.load(os.path.join(model_dir,dirs[i],tmp_dirs[0])))\n",
    "\n",
    "        print(\"model loaded\")\n",
    "        print(\"@@@@@@@@@@@@@@@@\")\n",
    "\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        tmp_type_preds, tmp_polarity_preds, tmp_tense_preds, tmp_certainty_preds = [], [], [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for input_ids, attention_mask in tqdm(test_loader):\n",
    "                input_ids = input_ids.to(device)\n",
    "                attention_mask = attention_mask.to(device)  \n",
    "\n",
    "                type_logit, polarity_logit, tense_logit, certainty_logit = model(input_ids, attention_mask)\n",
    "\n",
    "                soft_type_logit = softmax_layer(type_logit).detach().cpu()\n",
    "                soft_polarity_logit = softmax_layer(polarity_logit).detach().cpu()\n",
    "                soft_tense_logit = softmax_layer(tense_logit).detach().cpu()\n",
    "                soft_certainty_logit = softmax_layer(certainty_logit).detach().cpu()\n",
    "\n",
    "                if i==0:\n",
    "                    type_preds += soft_type_logit\n",
    "                    polarity_preds += soft_polarity_logit\n",
    "                    tense_preds += soft_tense_logit\n",
    "                    certainty_preds += soft_certainty_logit\n",
    "                else:\n",
    "                    tmp_type_preds += soft_type_logit\n",
    "                    tmp_polarity_preds += soft_polarity_logit\n",
    "                    tmp_tense_preds += soft_tense_logit\n",
    "                    tmp_certainty_preds += soft_certainty_logit\n",
    "\n",
    "        if i !=0:\n",
    "            for j in range(len(type_preds)):\n",
    "                type_preds[j] += tmp_type_preds[j]\n",
    "                polarity_preds[j] += tmp_polarity_preds[j]\n",
    "                tense_preds[j] += tmp_tense_preds[j]\n",
    "                certainty_preds[j] += tmp_certainty_preds[j]\n",
    "    \n",
    "    for k in range(len(type_preds)):\n",
    "        type_preds[k] = int(type_preds[k].argmax())\n",
    "        polarity_preds[k] = int(polarity_preds[k].argmax())\n",
    "        tense_preds[k] = int(tense_preds[k].argmax())\n",
    "        certainty_preds[k] = int(certainty_preds[k].argmax())\n",
    "\n",
    "    print(\"inference ensemble finished\")\n",
    "    print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "\n",
    "                    \n",
    "    return type_preds, polarity_preds, tense_preds, certainty_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@@@@@@\n",
      "['k0_roberta_document_sds', 'k1_roberta_document_sds', 'k2_roberta_document_sds', 'k3_roberta_document_sds', 'k4_roberta_document_sds']\n",
      "@@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@\n",
      "model_load start\n",
      "model : model_0_mean_f1.pth\n",
      "model_state_dict : model(best_scores)_0_mean_f1.pth\n",
      "model loaded\n",
      "@@@@@@@@@@@@@@@@\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61c4750a23e438db19fd7e69031fa5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@\n",
      "model_load start\n",
      "model : model_1_mean_f1.pth\n",
      "model_state_dict : model(best_scores)_1_mean_f1.pth\n",
      "model loaded\n",
      "@@@@@@@@@@@@@@@@\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1815681203914e46b301ab4a1baf1b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@\n",
      "model_load start\n",
      "model : model_2_mean_f1.pth\n",
      "model_state_dict : model(best_scores)_2_mean_f1.pth\n",
      "model loaded\n",
      "@@@@@@@@@@@@@@@@\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b99e76254f9453c97713ec54032a2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@\n",
      "model_load start\n",
      "model : model_3_mean_f1.pth\n",
      "model_state_dict : model(best_scores)_3_mean_f1.pth\n",
      "model loaded\n",
      "@@@@@@@@@@@@@@@@\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70299cabed484efdaefa9b3c76cf32e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@\n",
      "model_load start\n",
      "model : model_4_mean_f1.pth\n",
      "model_state_dict : model(best_scores)_4_mean_f1.pth\n",
      "model loaded\n",
      "@@@@@@@@@@@@@@@@\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f185363615bf409fb4dfe5545228577c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference ensemble finished\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@\n"
     ]
    }
   ],
   "source": [
    "type_preds, polarity_preds, tense_preds, certainty_preds = inference_ensemble(os.path.join(args.saved_path,args.model_name), test_loader, device)\n",
    "\n",
    "type_le = label_encoder['type']\n",
    "polarity_le = label_encoder['polarity']\n",
    "tense_le = label_encoder['tense']\n",
    "certainty_le = label_encoder['certainty']\n",
    "\n",
    "type_preds = type_le.inverse_transform(type_preds)\n",
    "polarity_preds = polarity_le.inverse_transform(polarity_preds)\n",
    "tense_preds = tense_le.inverse_transform(tense_preds)\n",
    "certainty_preds = certainty_le.inverse_transform(certainty_preds)\n",
    "\n",
    "predictions = []\n",
    "for type_pred, polarity_pred, tense_pred, certainty_pred in zip(type_preds, polarity_preds, tense_preds, certainty_preds):\n",
    "    predictions.append(type_pred+'-'+polarity_pred+'-'+tense_pred+'-'+certainty_pred)\n",
    "\n",
    "submit = pd.read_csv(os.path.join(args.data_path,'sample_submission.csv'))\n",
    "submit['label'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Finish\n"
     ]
    }
   ],
   "source": [
    "now_date = datetime.now()\n",
    "diff_hours = timedelta(hours=9)\n",
    "now_date += diff_hours\n",
    "print_now = str(now_date.month) + '_' + str(now_date.day) + '_' + str(now_date.hour) + '_' + str(now_date.minute)\n",
    "\n",
    "if not os.path.exists(args.output_path):\n",
    "    os.makedirs(args.output_path)\n",
    "\n",
    "if not os.path.exists(os.path.join(args.output_path,'soft_ensemble')):\n",
    "    os.makedirs(os.path.join(args.output_path,'soft_ensemble'))\n",
    "\n",
    "submit.to_csv(os.path.join(args.output_path,'soft_ensemble',f'{args.model_name}_{print_now}.csv'), index = False)\n",
    "\n",
    "print(\"Inference Finish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8bbb3e56-c6bb-41f3-aed1-0e6b2ff0a3c2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>bigyo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TEST_0008</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "      <td>사실형-긍정-미래-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TEST_0012</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "      <td>추론형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TEST_0018</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "      <td>추론형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>TEST_0042</td>\n",
       "      <td>추론형-긍정-미래-불확실</td>\n",
       "      <td>추론형-긍정-미래-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7020</th>\n",
       "      <td>TEST_7020</td>\n",
       "      <td>사실형-긍정-미래-불확실</td>\n",
       "      <td>사실형-긍정-미래-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>TEST_7032</td>\n",
       "      <td>추론형-긍정-현재-확실</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7077</th>\n",
       "      <td>TEST_7077</td>\n",
       "      <td>대화형-미정-과거-불확실</td>\n",
       "      <td>대화형-긍정-과거-불확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7083</th>\n",
       "      <td>TEST_7083</td>\n",
       "      <td>추론형-긍정-현재-불확실</td>\n",
       "      <td>추론형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7087</th>\n",
       "      <td>TEST_7087</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "      <td>사실형-긍정-미래-확실</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>510 rows × 3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8bbb3e56-c6bb-41f3-aed1-0e6b2ff0a3c2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-8bbb3e56-c6bb-41f3-aed1-0e6b2ff0a3c2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-8bbb3e56-c6bb-41f3-aed1-0e6b2ff0a3c2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "             ID          label          bigyo\n",
       "3     TEST_0003   사실형-긍정-과거-확실   사실형-긍정-현재-확실\n",
       "8     TEST_0008   사실형-긍정-현재-확실   사실형-긍정-미래-확실\n",
       "12    TEST_0012   사실형-긍정-과거-확실   추론형-긍정-과거-확실\n",
       "18    TEST_0018   사실형-긍정-과거-확실   추론형-긍정-과거-확실\n",
       "42    TEST_0042  추론형-긍정-미래-불확실   추론형-긍정-미래-확실\n",
       "...         ...            ...            ...\n",
       "7020  TEST_7020  사실형-긍정-미래-불확실   사실형-긍정-미래-확실\n",
       "7032  TEST_7032   추론형-긍정-현재-확실   사실형-긍정-현재-확실\n",
       "7077  TEST_7077  대화형-미정-과거-불확실  대화형-긍정-과거-불확실\n",
       "7083  TEST_7083  추론형-긍정-현재-불확실   추론형-긍정-현재-확실\n",
       "7087  TEST_7087   사실형-긍정-현재-확실   사실형-긍정-미래-확실\n",
       "\n",
       "[510 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigo = pd.read_csv('./results/hard_ensemble/hard_ensemble_final_submission_12_21_15_44.csv')\n",
    "submit['bigyo'] = bigo['label']\n",
    "submit[submit['label']!=submit['bigyo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
